{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LJCP3N1PMYz"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Nils Knieling, 2024 by Thorsten Staerk\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo0T-oS4qIcZ"
      },
      "source": [
        "# Gemini\n",
        "\n",
        "[![Open in Colab](https://img.shields.io/badge/Open%20in%20Colab-%23F9AB00.svg?logo=googlecolab&logoColor=white)](https://colab.research.google.com/github/tstaerk/toolbox/blob/master/notebooks/Gemini.ipynb)\n",
        "[![Open in Vertex AI Workbench](https://img.shields.io/badge/Open%20in%20Vertex%20AI%20Workbench-%234285F4.svg?logo=googlecloud&logoColor=white)](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/tstaerk/toolbox/master/notebooks/Gemini.ipynb)\n",
        "[![View on GitHub](https://img.shields.io/badge/View%20on%20GitHub-181717.svg?logo=github&logoColor=white)](https://github.com/tstaerk/toolbox/blob/master/notebooks/Gemini.ipynb)\n",
        "\n",
        "This is my first notebook. Goal is to use GenAI to OCR tables in PDFs we are regularly getting.\n",
        "As an intermediate goal, I want to OCR a text in a jpeg image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uit1SQshQ9KK"
      },
      "source": [
        "## Install required packages\n",
        "\n",
        ">⚠️ You may receive a warning to \"Restart Runtime\" after the packages are installed. Don't worry, the subsequent cells will help you restart the runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "FffwLH09RBkG",
        "outputId": "64a7309c-aa51-411f-dcf9-e8ed7310596b"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Install dependencies\n",
        "\n",
        "!pip install --upgrade google-cloud-aiplatform\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
       "metadata": {
        "id": "Uit1SQshQ9KK"
      },
      "source": [
        "## Install required packages\n",
        "\n",
        ">⚠️ You may receive a warning that there was a crash. This is intended, we do a shutdown so the env gets reloaded."
      ]
    },

    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlY4PlzQVZw7",
        "outputId": "71ea6e40-4af4-48b8-cffd-8c20b8cce00d"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Restart\n",
        "\n",
        "# Automatically restart kernel after installs so that your environment\n",
        "# can access the new packages.\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnruz3TtRcxT"
      },
      "source": [
        "## Setup Google Cloud environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tMXbXBtRd5d",
        "outputId": "bedccf40-75c8-4f5f-a55f-10c9de09aa7c"
      },
      "outputs": [],
      "source": [
        "# @markdown ✏️ Replace the placeholder text below:\n",
        "\n",
        "# Please fill in these values.\n",
        "project_id = \"your-project-id\"  # @param {type:\"string\"}\n",
        "region = \"us-central1\"  # @param {type:\"string\"}\n",
        "vision_model = \"gemini-pro-vision\" # @param {type:\"string\"}\n",
        "text_model = \"gemini-pro\" # @param {type:\"string\"}\n",
        "code_model = \"code-bison\" # @param {type:\"string\"}\n",
        "\n",
        "llm_temperature = 0.4 # @param {type:\"number\"}\n",
        "\n",
        "# Quick input validations.\n",
        "assert project_id, \"⚠️ Please provide a Google Cloud project ID\"\n",
        "assert region, \"⚠️ Please provide a Google Cloud region\"\n",
        "assert vision_model, \"⚠️ Please provide a pretrained LLM\"\n",
        "assert text_model, \"⚠️ Please provide a pretrained LLM\"\n",
        "assert code_model, \"⚠️ Please provide a pretrained LLM\"\n",
        "assert llm_temperature, \"⚠️ Please provide a temperature\"\n",
        "\n",
        "llm_config={\n",
        "  \"max_output_tokens\": 256,\n",
        "  \"temperature\": llm_temperature,\n",
        "  \"top_p\": 1,\n",
        "  \"top_k\": 32\n",
        "}\n",
        "\n",
        "# Configure gcloud.\n",
        "!gcloud config set project \"{project_id}\"\n",
        "!gcloud config set storage/parallel_composite_upload_enabled \"True\"\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dPxoA5LER7jA"
      },
      "outputs": [],
      "source": [
        "#@markdown ### (Colab only!) Authenticate your Google Cloud Account\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smHnC3JRR_SC",
        "outputId": "c29040e6-64f8-4347-9961-1dd80f1916ee"
      },
      "outputs": [],
      "source": [
        "#@markdown ###  Check authenticated user\n",
        "\n",
        "current_user = !gcloud auth list \\\n",
        "  --filter=\"status:ACTIVE\" \\\n",
        "  --format=\"value(account)\" \\\n",
        "  --quiet\n",
        "\n",
        "current_user = current_user[0]\n",
        "print(f\"Current user: {current_user}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgmGIoZfSC5L",
        "outputId": "c5596528-327a-40c2-83e9-6bd31bddcde8"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Enable APIs\n",
        "\n",
        "# Enable APIs\n",
        "my_google_apis = [\n",
        "    \"aiplatform.googleapis.com\",\n",
        "]\n",
        "\n",
        "for api in my_google_apis :\n",
        "  print(f\"Enable API: {api}\")\n",
        "  !gcloud services enable \"{api}\" \\\n",
        "    --project=\"{project_id}\" \\\n",
        "    --quiet\n",
        "\n",
        "print(\"☑️ OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMMkHzLUm-D2"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPqGLPGBjnNX",
        "outputId": "39b85766-1574-4b67-d750-2a0bcd2e99ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "☑️ Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "☑️ Vertex AI SDK version: 1.38.1\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### Import and print versions\n",
        "\n",
        "import sys\n",
        "print(f\"☑️ Python: {sys.version}\")\n",
        "\n",
        "# Vertex AI\n",
        "import vertexai\n",
        "from google.cloud import aiplatform\n",
        "from vertexai.preview.generative_models import GenerativeModel, Part\n",
        "from vertexai.language_models import CodeGenerationModel\n",
        "\n",
        "print(f\"☑️ Vertex AI SDK version: {aiplatform.__version__}\")\n",
        "\n",
        "vertexai.init(\n",
        "    project=project_id,\n",
        "    location=region,\n",
        ")\n",
        "\n",
        "visionModel = GenerativeModel(vision_model)\n",
        "textModel = GenerativeModel(vision_model)\n",
        "codeModel = CodeGenerationModel.from_pretrained(code_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9JZzQZB-SG2h",
        "outputId": "4c77a447-9482-4c24-c6a7-052eb297f4f3"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Import images\n",
        "\n",
        "import base64\n",
        "from IPython.display import Image, HTML, display\n",
        "\n",
        "print(\"Download images...\")\n",
        "\n",
        "images = ['to-ocr.png']\n",
        "\n",
        "for image in images:\n",
        "  !curl -o \"{image}\" \"https://raw.githubusercontent.com/tstaerk/toolbox/master/notebooks/gemini/{image}\"\n",
        "  display(Image(image, width=100))\n",
        "\n",
        "with open(images[0], \"rb\") as image_file_hand_close:\n",
        "  base64_hand_close = base64.b64encode(image_file_hand_close.read())\n",
        "image0 = Part.from_data(data=base64.b64decode(base64_hand_close), mime_type=\"image/png\")\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BiU-6MknETb"
      },
      "source": [
        "## Describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "mGUOaJaYnH68",
        "outputId": "65ee5528-5ca9-4292-e136-9f7493e3cd99"
      },
      "outputs": [],
      "source": [
        "#@markdown #### Describe images\n",
        "\n",
        "prompt = \"What is written in the image?\"\n",
        "\n",
        "print(prompt)\n",
        "\n",
        "display(Image(images[0], width=100))\n",
        "response = visionModel.generate_content(\n",
        "  [prompt, image0],\n",
        "  generation_config=llm_config\n",
        ")\n",
        "print(response.candidates[0].content.parts[0].text)\n",
        "\n",
        "print(\"☑️ Done\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
